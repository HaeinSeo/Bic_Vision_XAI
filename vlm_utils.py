"""
VLM (Vision Language Model) ìœ í‹¸ë¦¬í‹°
- LLaVA / BLIP / GIT ê¸°ë°˜ ì´ë¯¸ì§€ ì„¤ëª…
- AI ì˜ˆì¸¡ + SHAP/LIME íŠ¹ì§• ìš”ì•½
- ì´ë¯¸ì§€ ê¸°ë°˜ ì„¸í¬ í˜•íƒœ ì •ëŸ‰ ë¶„ì„(analyze_morphology)ê¹Œì§€ ë¶™ì—¬ì„œ
  ë³‘ë¦¬í•™ì ìœ¼ë¡œ ì½ê¸° ì‰¬ìš´ ë¦¬í¬íŠ¸ í˜•íƒœë¡œ ì¶œë ¥
"""

from PIL import Image
import os

# ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆì—ì„œ í˜•íƒœ ì •ëŸ‰ ë¶„ì„ í•¨ìˆ˜ë§Œ ê°€ì ¸ì˜´
from image_utils import analyze_morphology


class VLMExplainer:
    """
    LLaVA / BLIP / GIT ê¸°ë°˜ ì´ë¯¸ì§€ ì„¤ëª… + ëª¨ë¸ íŠ¹ì§• ìš”ì•½ + í˜•íƒœ ì •ëŸ‰ ë¶„ì„ ë¦¬í¬íŠ¸
    """

    def __init__(self, model_name="llava-hf/llava-1.5-7b-hf", device=None):
        self.model_name = model_name
        self.device = None
        self.model = None
        self.processor = None

        # 1) torch / device ì„¤ì •
        try:
            import torch
            # torch ë²„ì „ ì²´í¬
            torch_version = torch.__version__
            major, minor = map(int, torch_version.split('.')[:2])
            if major < 2 or (major == 2 and minor < 6):
                print(f"âš ï¸ torch ë²„ì „ì´ ë‚®ìŠµë‹ˆë‹¤ (í˜„ì¬: {torch_version}, í•„ìš”: >= 2.6)")
                print("ğŸ’¡ pip install --upgrade torch torchvision torchaudio")
            
            if device is not None:
                self.device = device
            else:
                if torch.cuda.is_available():
                    self.device = "cuda"
                    print("âœ… GPU ê°ì§€:", torch.cuda.get_device_name(0))
                    print("âœ… CUDA ë²„ì „:", torch.version.cuda)
                else:
                    self.device = "cpu"
                    print("âš ï¸ GPU ë¯¸ì‚¬ìš©, CPU ì‚¬ìš©")
        except Exception as e:
            print(f"âš ï¸ torch ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
            return

        # 2) ëª¨ë¸ ë¡œë“œ
        self._load_model()

    # ------------------------------------------------------------------
    # ëª¨ë¸ ë¡œë“œ
    # ------------------------------------------------------------------
    def _load_model(self):
        try:
            import torch
            from transformers import AutoProcessor, AutoModelForVision2Seq

            print(f"VLM ëª¨ë¸ ë¡œë“œ ì‹œë„ (device={self.device})")

            # ì‘ì€ ëª¨ë¸ë¶€í„° ì‹œë„ (ë©”ëª¨ë¦¬ ë¬¸ì œ ë°©ì§€)
            # torch ë²„ì „ ë¬¸ì œë¡œ blip-image-captioning-baseëŠ” ì œì™¸
            candidates = [
                "microsoft/git-base",
                "llava-hf/llava-1.5-7b-hf",
            ]

            last_error = None
            for name in candidates:
                try:
                    print(f"ğŸ” ëª¨ë¸ í›„ë³´: {name}")
                    # use_fast=False ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ê²½ê³  ë°©ì§€
                    processor = AutoProcessor.from_pretrained(
                        name, trust_remote_code=True, use_fast=False
                    )
                    kwargs = {
                        "trust_remote_code": True,
                        "low_cpu_mem_usage": True,
                    }
                    if self.device == "cuda":
                        kwargs["torch_dtype"] = torch.float16
                        kwargs["device_map"] = "auto"
                    else:
                        kwargs["torch_dtype"] = torch.float32

                    model = AutoModelForVision2Seq.from_pretrained(name, **kwargs)
                    if self.device == "cpu":
                        model = model.to(self.device)

                    self.model_name = name
                    self.processor = processor
                    self.model = model.eval()

                    print(f"âœ… VLM ë¡œë“œ ì„±ê³µ: {name}")
                    return
                except Exception as e:
                    last_error = e
                    error_msg = str(e)
                    # torch ë²„ì „ ê´€ë ¨ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                    if "torch.load" in error_msg or "torch 2.6" in error_msg.lower():
                        print(f"âš ï¸ {name} ë¡œë“œ ì‹¤íŒ¨ (torch ë²„ì „ ë¬¸ì œ): ë‹¤ìŒ ëª¨ë¸ ì‹œë„...")
                    else:
                        print(f"âš ï¸ {name} ë¡œë“œ ì‹¤íŒ¨: {error_msg[:200]}")

            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ VLM ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            if last_error:
                print("  ë§ˆì§€ë§‰ ì˜¤ë¥˜:", last_error)

        except Exception as e:
            print(f"âš ï¸ transformers/ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None
            self.processor = None

    # ------------------------------------------------------------------
    # ìœ íš¨ì„± ì²´í¬
    # ------------------------------------------------------------------
    def is_available(self):
        return self.model is not None and self.processor is not None

    # ------------------------------------------------------------------
    # ë‚´ë¶€: í˜•íƒœ ì •ëŸ‰ ë¶„ì„ (VLM í”„ë¡¬í”„íŠ¸ & ë¦¬í¬íŠ¸ìš©)
    # ------------------------------------------------------------------
    def _compute_morphology_summary(self, image_path):
        try:
            return analyze_morphology(image_path)
        except Exception as e:
            print(f"âš ï¸ í˜•íƒœ ì •ëŸ‰ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    # ------------------------------------------------------------------
    # ë©”ì¸: ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±
    # ------------------------------------------------------------------
    def explain_image(self, image_path, prediction_result=None, features_info=None):
        """
        ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ìƒì„±:
        - VLM ìº¡ì…˜ (ì˜í•™ì  ì‚¬ì „ ì§€ì‹ + ì •ëŸ‰ ë¶„ì„ í¬í•¨ í”„ë¡¬í”„íŠ¸)
        - ì˜ˆì¸¡/íŠ¹ì§• ìš”ì•½
        - ì„¸í¬ í˜•íƒœ ì •ëŸ‰ ë¶„ì„ ë¦¬í¬íŠ¸
        ==> í•˜ë‚˜ì˜ markdown ë¬¸ìì—´ë¡œ ë°˜í™˜
        """
        # 0) í˜•íƒœ ì •ëŸ‰ ë¶„ì„
        morph_summary = self._compute_morphology_summary(image_path)

        vlm_text = None

        if self.is_available():
            try:
                vlm_text = self._run_vlm(
                    image_path, prediction_result, features_info, morph_summary
                )
            except Exception as e:
                print(f"âš ï¸ VLM ì¶”ë¡  ì¤‘ ì˜¤ë¥˜: {e}")
                vlm_text = None

        if not vlm_text:
            vlm_text = self._generate_fallback_visual_description()

        summary_text = self._build_prediction_feature_summary(
            prediction_result, features_info
        )
        morph_md = self._build_morphology_summary_md(morph_summary)

        final_md = "## ì´ë¯¸ì§€ ê¸°ë°˜ ì„¤ëª… (VLM)\n\n"
        final_md += vlm_text.strip() + "\n\n"
        final_md += "---\n\n"
        final_md += summary_text.strip()
        if morph_md:
            final_md += "\n\n---\n\n" + morph_md.strip()

        print("\n================= [VLM ìµœì¢… ì„¤ëª…] =================")
        print(final_md[:1500])
        print("==================================================\n")

        return final_md

    # ------------------------------------------------------------------
    # ë‚´ë¶€: ì‹¤ì œ VLM í˜¸ì¶œ
    # ------------------------------------------------------------------
    def _run_vlm(
        self,
        image_path,
        prediction_result=None,
        features_info=None,
        morph_summary=None
    ):
        import torch

        # ì´ë¯¸ì§€ ë¡œë“œ
        if isinstance(image_path, str):
            if not os.path.exists(image_path):
                print(f"âš ï¸ ì´ë¯¸ì§€ ê²½ë¡œ ì—†ìŒ: {image_path}")
                return None
            image = Image.open(image_path).convert("RGB")
        else:
            image = image_path  # ì´ë¯¸ PIL.Image ì¸ìŠ¤í„´ìŠ¤ë¡œ ë„˜ì–´ì˜¤ëŠ” ê²½ìš°

        # í•´ìƒë„ ì œí•œ(ë©”ëª¨ë¦¬ ë³´í˜¸)
        max_size = 1024
        if image.size[0] > max_size or image.size[1] > max_size:
            ratio = min(max_size / image.size[0], max_size / image.size[1])
            new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
            image = image.resize(new_size, Image.Resampling.LANCZOS)

        prompt = self._build_prompt(prediction_result, features_info, morph_summary)

        print(f"ğŸ“¸ VLM ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘ (size={image.size}, model={self.model_name})")

        # BLIP / GIT ê³„ì—´: ìº¡ì…”ë‹ ë°©ì‹
        if "blip" in self.model_name.lower() or "git" in self.model_name.lower():
            # í”„ë¡¬í”„íŠ¸ë¥¼ ë” ì§§ê²Œ ë§Œë“¤ê¸°
            short_prompt = self._build_short_prompt(prediction_result, features_info, morph_summary)
            text_prompt = (
                "ì´ê²ƒì€ ìœ ë°©ì•” ì„¸í¬ í˜„ë¯¸ê²½ ì‚¬ì§„ì…ë‹ˆë‹¤. "
                "ì„¸í¬ì˜ í˜•íƒœ, í¬ê¸°, ë°°ì—´, í•µì˜ íŠ¹ì§•ì„ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n\n"
                + short_prompt
            )
            inputs = self.processor(images=image, text=text_prompt, return_tensors="pt")
            inputs = {
                k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                for k, v in inputs.items()
            }

            with torch.no_grad():
                # ì…ë ¥ ê¸¸ì´ í™•ì¸ ë° max_new_tokens ì„¤ì •
                input_length = inputs['input_ids'].shape[1] if 'input_ids' in inputs else 0
                # ëª¨ë¸ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ê³ ë ¤í•˜ì—¬ ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •
                max_model_length = 512  # GIT/BLIP ëª¨ë¸ì˜ ì¼ë°˜ì ì¸ ìµœëŒ€ ê¸¸ì´
                if input_length > max_model_length - 100:
                    # ì…ë ¥ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
                    print(f"âš ï¸ ì…ë ¥ í† í° ê¸¸ì´({input_length})ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¨ì¶•í•©ë‹ˆë‹¤.")
                    # ë” ì§§ì€ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
                    text_prompt = "ì´ê²ƒì€ ìœ ë°©ì•” ì„¸í¬ í˜„ë¯¸ê²½ ì‚¬ì§„ì…ë‹ˆë‹¤. ì„¸í¬ì˜ í˜•íƒœì™€ í•µì˜ íŠ¹ì§•ì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                    inputs = self.processor(images=image, text=text_prompt, return_tensors="pt")
                    inputs = {
                        k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                        for k, v in inputs.items()
                    }
                    input_length = inputs['input_ids'].shape[1] if 'input_ids' in inputs else 0
                
                max_new_tokens = min(256, max(50, max_model_length - input_length - 50))
                
                generated_ids = self.model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    num_beams=5,
                    early_stopping=True,
                )

            text = self.processor.batch_decode(
                generated_ids, skip_special_tokens=True
            )[0].strip()

            if text.startswith(text_prompt):
                text = text[len(text_prompt):].strip()

            print(f"ğŸ“ VLM ì›ë³¸ ìº¡ì…˜: {text[:200]}...")
            return text if text else None

        # LLaVA ê³„ì—´: ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸
        else:
            # í”„ë¡¬í”„íŠ¸ë¥¼ ë” ì§§ê²Œ ë§Œë“¤ê¸°
            short_prompt = self._build_short_prompt(prediction_result, features_info, morph_summary)
            inputs = self.processor(
                images=image,
                text=short_prompt,
                return_tensors="pt"
            )
            inputs = {
                k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                for k, v in inputs.items()
            }

            with torch.no_grad():
                # ì…ë ¥ ê¸¸ì´ í™•ì¸ ë° max_new_tokens ì„¤ì •
                input_length = inputs['input_ids'].shape[1] if 'input_ids' in inputs else 0
                # ëª¨ë¸ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ê³ ë ¤í•˜ì—¬ ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •
                max_model_length = 2048  # LLaVA ëª¨ë¸ì˜ ì¼ë°˜ì ì¸ ìµœëŒ€ ê¸¸ì´
                if input_length > max_model_length - 200:
                    # ì…ë ¥ì´ ë„ˆë¬´ ê¸¸ë©´ ë” ì§§ì€ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
                    print(f"âš ï¸ ì…ë ¥ í† í° ê¸¸ì´({input_length})ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¨ì¶•í•©ë‹ˆë‹¤.")
                    short_prompt = "ì´ê²ƒì€ ìœ ë°©ì•” ì„¸í¬ í˜„ë¯¸ê²½ ì‚¬ì§„ì…ë‹ˆë‹¤. ì„¸í¬ì˜ í˜•íƒœì™€ í•µì˜ íŠ¹ì§•ì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                    inputs = self.processor(images=image, text=short_prompt, return_tensors="pt")
                    inputs = {
                        k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                        for k, v in inputs.items()
                    }
                    input_length = inputs['input_ids'].shape[1] if 'input_ids' in inputs else 0
                
                max_new_tokens = min(1024, max(50, max_model_length - input_length - 100))
                
                generated_ids = self.model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.9,
                    pad_token_id=(
                        self.processor.tokenizer.eos_token_id
                        if hasattr(self.processor, "tokenizer")
                        else None
                    ),
                )

            text = self.processor.batch_decode(
                generated_ids, skip_special_tokens=True
            )[0].strip()

            print(f"ğŸ“ VLM ì›ë³¸ ì‘ë‹µ: {text[:200]}...")
            text = text.replace("</s>", "").replace("<pad>", "").strip()
            return text if text else None

    # ------------------------------------------------------------------
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ìœ ë°©ì•” ì„¸í¬ íŠ¹ì§• + ì˜ˆì¸¡ê²°ê³¼ + í˜•íƒœ ì •ëŸ‰ ë¶„ì„)
    # ------------------------------------------------------------------
    def _build_prompt(self, prediction_result=None, features_info=None,
                      morph_summary=None):
        # ë³‘ë¦¬í•™ì  ì„¤ëª…ì„ ìœ„í•œ base í…ìŠ¤íŠ¸
        base = """ì´ê²ƒì€ ìœ ë°©ì•” ì„¸í¬ í˜„ë¯¸ê²½ ì‚¬ì§„ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ã€ì–‘ì„±(Benign) ì„¸í¬ì˜ ì „í˜•ì  íŠ¹ì§•ã€‘
- ë¹„êµì  ê· ì¼í•œ ì„¸í¬ í¬ê¸°ì™€ ëª¨ì–‘ (ì €ë„/ê²½ë„ ì„¸í¬ ì´í˜•ì„±)
- ì„¸í¬ê°€ êµ°ì§‘ì„ ì´ë£¨ë”ë¼ë„ ê²½ê³„ê°€ ë¹„êµì  ë§¤ë„ëŸ½ê³ , í•µ/ì„¸í¬ì§ˆ ë¹„ìœ¨(N/C ratio)ì´ ë‚®ìŒ
- í•µ í¬ê¸°ê°€ ì„œë¡œ ë¹„ìŠ·í•˜ê³ , ì—¼ìƒ‰ ê°•ë„(chromatin)ê°€ ê³ ë¥´ê²Œ ë¶„í¬í•˜ë©° ê³¼ë„í•˜ê²Œ ì–´ë‘¡ì§€ ì•ŠìŒ
- ë¶„ì—´ìƒ(mitotic figure)ì´ ê±°ì˜ ë³´ì´ì§€ ì•Šê±°ë‚˜ ë“œë¬¾
- ì„¸í¬ ì‚¬ì´ ê°„ê²©ì´ ì–´ëŠ ì •ë„ ìœ ì§€ë˜ê³ , ì¡°ì§ êµ¬ì¡°ê°€ ë¹„êµì  ë³´ì¡´ë¨

ã€ì•…ì„±(Malignant) ì„¸í¬ì˜ ì „í˜•ì  íŠ¹ì§•ã€‘
- í¬ê¸°ê°€ ì„œë¡œ ë‹¤ë¥¸ ì„¸í¬ë“¤ì´ ì„ì—¬ ìˆëŠ” ë‹¤í˜•ì„±(nuclear pleomorphism)
- í•µ/ì„¸í¬ì§ˆ ë¹„ìœ¨(N/C ratio)ì´ ì¦ê°€í•˜ê³ , í•µì´ ë¹„ì •ìƒì ìœ¼ë¡œ í¬ê±°ë‚˜ ì°Œê·¸ëŸ¬ì ¸ ë³´ì„
- í•µë§‰(nuclear membrane)ì´ ë¶ˆê·œì¹™í•˜ê³ , ì—¼ìƒ‰ ê°•ë„ê°€ ì§„í•˜ê±°ë‚˜ ê±°ì¹ ê²Œ ë¶„í¬(coarse chromatin)
- ëšœë ·í•œ í•µì†Œì²´(prominent nucleoli)ê°€ ê´€ì°°ë˜ëŠ” ê²½ìš°ê°€ ë§ìŒ
- ì„¸í¬ë“¤ì´ ì¡°ë°€í•˜ê²Œ êµ°ì§‘í•˜ê±°ë‚˜, ì‹œíŠ¸(sheet) í˜•íƒœ ë˜ëŠ” ë¬´ì§ˆì„œí•œ ë°°ì—´ì„ ë³´ì´ë©° ì£¼ë³€ ì¡°ì§ê³¼ì˜ ê²½ê³„ê°€ ë¶ˆëª…í™•í•´ì§
- ë¶„ì—´ìƒ(mitosis)ì´ ì¦ê°€í•˜ë©°, ë¹„ì •í˜• ë¶„ì—´ìƒ(atypical mitosis)ì´ ê´€ì°°ë  ìˆ˜ ìˆìŒ
"""

        # ì´ë¯¸ì§€ ê¸°ë°˜ ì •ëŸ‰ ë¶„ì„ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        if morph_summary and morph_summary.get("total_cells", 0) > 0:
            total = morph_summary["total_cells"]
            ir_cnt = morph_summary["irregular_boundary_cells"]
            ir_ratio = morph_summary["irregular_boundary_ratio"] * 100
            lg_cnt = morph_summary["large_cells"]
            lg_ratio = morph_summary["large_cell_ratio"] * 100
            hc_cnt = morph_summary["high_contrast_cells"]
            hc_ratio = morph_summary["high_contrast_ratio"] * 100

            base += "\nã€ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê¸°ë°˜ ì„¸í¬ í˜•íƒœ ì •ëŸ‰ ë¶„ì„ ìš”ì•½ã€‘\n"
            base += f"- ê°ì§€ëœ ì„¸í¬ ìˆ˜: {total}ê°œ\n"
            base += f"- ê²½ê³„ê°€ ë“¤ì‘¥ë‚ ì‘¥í•œ(ë¶ˆê·œì¹™í•œ) ì„¸í¬: ì•½ {ir_ratio:.1f}% ({ir_cnt}ê°œ)\n"
            base += f"- ìƒëŒ€ì ìœ¼ë¡œ í° ì„¸í¬(ë©´ì  ìƒìœ„ 25%): ì•½ {lg_ratio:.1f}% ({lg_cnt}ê°œ)\n"
            base += f"- í…ìŠ¤ì²˜ ëŒ€ë¹„(ëª…ì•” ë³€í™”)ê°€ ë†’ì€ ì„¸í¬: ì•½ {hc_ratio:.1f}% ({hc_cnt}ê°œ)\n"
            base += "- ì¼ë°˜ì ìœ¼ë¡œ ì•…ì„±ìœ¼ë¡œ ê°ˆìˆ˜ë¡ ê²½ê³„ê°€ ë¶ˆê·œì¹™í•œ ì„¸í¬ì™€ í° ì„¸í¬, í•µ ì—¼ìƒ‰ì´ ì§„í•œ ì„¸í¬ì˜ ë¹„ìœ¨ì´ ì¦ê°€í•©ë‹ˆë‹¤.\n"

        # ì˜ˆì¸¡ ê²°ê³¼
        if prediction_result:
            pred = prediction_result.get("prediction", "")
            malignant_prob = prediction_result.get("malignant_prob", 0)
            benign_prob = prediction_result.get("benign_prob", 0)
            base += f"\nã€AI ì˜ˆì¸¡ ê²°ê³¼(ì°¸ê³ ìš©)ã€‘\nAI ì˜ˆì¸¡: {pred} (ì•…ì„± {malignant_prob:.1%}, ì–‘ì„± {benign_prob:.1%})\n"

        # XAI ìƒìœ„ íŠ¹ì§• ì´ë¦„ íŒíŠ¸
        if features_info and features_info.get("top_features"):
            base += "\nã€ëª¨ë¸ì´ ì¤‘ìš”í•˜ê²Œ ë³¸ ì •ëŸ‰ íŠ¹ì§•(ìƒìœ„ ì¼ë¶€)ã€‘\n"
            names = [f["feature"] for f in features_info["top_features"][:3]]
            base += "- ì˜ˆ: " + ", ".join(names) + "\n"
            base += "ì´ë“¤ íŠ¹ì§•ì€ ì¢…ì–‘ì˜ í¬ê¸°(radius/area/perimeter), ê²½ê³„ ë¶ˆê·œì¹™ì„±(concavity/convexity), í•µ ì£¼ë³€ ì§ˆê°(texture contrast/homogeneity) ë“±ì„ ë°˜ì˜í•©ë‹ˆë‹¤.\n"

        # ì˜í•™ì  ì¶”ë¡ ì„ ìš”êµ¬í•˜ëŠ” êµ¬ì²´ ì§ˆë¬¸
        base += """
ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ê´€ì°°í•˜ê³ , ìœ„ì˜ ë³‘ë¦¬í•™ì  íŠ¹ì§•ê³¼ ì •ëŸ‰ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒì„ í•œêµ­ì–´ë¡œ **ì°¨ë¶„í•˜ê²Œ, ë³‘ë¦¬ê³¼ ì˜ì‚¬ê°€ êµ¬ë‘ ì†Œê²¬ì„ ê¸°ìˆ í•˜ë“¯** ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ê°€ëŠ¥í•˜ë©´ ì¶”ìƒì ì¸ í‘œí˜„ ëŒ€ì‹ , ì‹¤ì œë¡œ ëˆˆì— ë³´ì´ëŠ” ì–‘ìƒì„ ê·¼ê±°ë¡œ ì„œìˆ í•´ì£¼ì„¸ìš”.

1. **ì„¸í¬ í¬ê¸°ì™€ ëª¨ì–‘**
   - ì„¸í¬ í¬ê¸°ê°€ ì „ë°˜ì ìœ¼ë¡œ ê· ì¼í•œì§€, í¬ê¸°ê°€ ë§¤ìš° ë‹¤ì–‘í•œì§€(ê²½ë„/ì¤‘ë“±ë„/ê³ ë„ ì„¸í¬ ì´í˜•ì„± ì¤‘ ì–´ë””ì— ê°€ê¹Œìš´ì§€) ì„œìˆ í•´ì£¼ì„¸ìš”.
   - ì›í˜•ì— ê°€ê¹Œìš´ ì„¸í¬ê°€ ë§ì€ì§€, ì°Œê·¸ëŸ¬ì§„/ê¸¸ê²Œ ëŠ˜ì–´ë‚œ ì„¸í¬ê°€ ë§ì€ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

2. **í•µì˜ í˜•íƒœì™€ ì—¼ìƒ‰ ì–‘ìƒ**
   - í•µì˜ í¬ê¸°ì™€ ëª¨ì–‘ì´ ì„œë¡œ ë¹„ìŠ·í•œì§€, í¬ê¸° ì°¨ì´ê°€ í°ì§€(í•µ ë‹¤í˜•ì„±) ê¸°ìˆ í•´ì£¼ì„¸ìš”.
   - í•µ ì—¼ìƒ‰ ê°•ë„(chromatin)ê°€ ê· ì¼í•œì§€, ì¼ë¶€ ì„¸í¬ì—ì„œ ìœ ë‚œíˆ ì§„í•˜ê±°ë‚˜ ê±°ì¹œ íŒ¨í„´ì´ ë³´ì´ëŠ”ì§€,
     ëšœë ·í•œ í•µì†Œì²´ê°€ ë³´ì´ëŠ” ì„¸í¬ê°€ ë§ì€ì§€ ê´€ì°°í•œ ëŒ€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

3. **í•µ/ì„¸í¬ì§ˆ ë¹„ìœ¨(N/C ratio)ê³¼ ì„¸í¬ ë°°ì—´**
   - ì„¸í¬ì§ˆì— ë¹„í•´ í•µì´ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ì´ ì „ë°˜ì ìœ¼ë¡œ ë‚®ì€ì§€/ë†’ì€ì§€, ì•…ì„±ì— ê°€ê¹Œìš´ íŒ¨í„´ì¸ì§€ íŒë‹¨í•´ ë³´ì„¸ìš”.
   - ì„¸í¬ë“¤ì´ ëŠìŠ¨í•˜ê²Œ í¼ì ¸ ìˆëŠ”ì§€, êµ°ì§‘Â·ì‹œíŠ¸(sheet)Â·ì¤‘ì²©ëœ ë°°ì—´ë¡œ ë°€ì§‘ë˜ì–´ ìˆëŠ”ì§€,
     ë‹¨ì¼ ì„¸í¬(single cell)ë“¤ì´ ë§ì´ ë–¨ì–´ì ¸ ë³´ì´ëŠ” ì–‘ìƒì¸ì§€ ì„œìˆ í•´ì£¼ì„¸ìš”.

4. **ê²½ê³„ ë¶ˆê·œì¹™ì„±ê³¼ ì£¼ë³€ ì¡°ì§ê³¼ì˜ ê´€ê³„**
   - ì„¸í¬ ë˜ëŠ” êµ°ì§‘ì˜ ì™¸ê³½ ê²½ê³„ê°€ ë§¤ë„ëŸ¬ìš´ì§€, í†±ë‹ˆ ëª¨ì–‘/ë¶ˆê·œì¹™í•œì§€ ì„œìˆ í•´ì£¼ì„¸ìš”.
   - ì •ëŸ‰ ë¶„ì„ì—ì„œ ì œì‹œëœ 'ê²½ê³„ê°€ ë“¤ì‘¥ë‚ ì‘¥í•œ ì„¸í¬ ë¹„ìœ¨'ì´ ì‹¤ì œ ëˆˆìœ¼ë¡œ ë³´ì´ëŠ” ê²½ê³„ ë¶ˆê·œì¹™ì„±ê³¼ ì˜ ë§ëŠ”ì§€,
     í˜¹ì€ íŠ¹ì • ì˜ì—­ì— ì§‘ì¤‘ë˜ì–´ ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

5. **ì„¸í¬ í¬ê¸° ë¶„í¬ì™€ ë‹¤í˜•ì„±**
   - 'í° ì„¸í¬ ë¹„ìœ¨'ì´ ë†’ì€ ê²½ìš°, ì‹¤ì œë¡œ í° ì„¸í¬ë“¤ì´ ì–´ëŠ ì˜ì—­ì— ì§‘ì¤‘ë˜ëŠ”ì§€,
     ì‘ì€ ì„¸í¬ì™€ ì„ì—¬ ìˆëŠ” ë‹¤í˜•ì„± íŒ¨í„´ìœ¼ë¡œ ë³´ì´ëŠ”ì§€ ê´€ì°°í•œ ëŒ€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

6. **ì—¼ìƒ‰ ë†ë„ì™€ í…ìŠ¤ì²˜**
   - ê³ ëŒ€ë¹„ í…ìŠ¤ì²˜ ì„¸í¬ ë¹„ìœ¨ì´ ë†’ì€ ê²½ìš°, í•µ ë˜ëŠ” ì„¸í¬ì§ˆì—ì„œ ëª…ì•” ì°¨ì´ê°€ ë‘ë“œëŸ¬ì§€ëŠ” ë¶€ìœ„ê°€ ìˆëŠ”ì§€,
     ê´´ì‚¬(central necrosis)ë‚˜ ì—¼ì¦ì„± ì„¸í¬ ì¹¨ìœ¤ì´ ì˜ì‹¬ë˜ëŠ” ì˜ì—­ì´ ìˆëŠ”ì§€ ê°„ë‹¨íˆ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.

7. **ì¢…í•©ì  ì¸ìƒ**
   - ìœ„ì˜ ì†Œê²¬ì„ ì¢…í•©í–ˆì„ ë•Œ, ì „í˜•ì ì¸ ì–‘ì„± ë³€í™”ì— ê°€ê¹Œìš´ì§€, 'ë¹„ì •í˜•ì´ ë™ë°˜ëœ ì–‘ì„± ë³€í™”'ì¸ì§€,
     í˜¹ì€ ì•…ì„± ë³‘ë³€ì— ë” ê°€ê¹Œìš´ ì¸ìƒì¸ì§€ **ì§„ë‹¨ëª…ì€ ì–¸ê¸‰í•˜ì§€ ë§ê³ **, 
     "ì•…ì„±ì— ê°€ê¹Œìš´ ì†Œê²¬", "ì „í˜•ì  ì–‘ì„±ì— ê°€ê¹Œìš´ ì†Œê²¬" ë“±ì˜ í‘œí˜„ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
"""
        return base

    # ------------------------------------------------------------------
    # ì§§ì€ í”„ë¡¬í”„íŠ¸ ìƒì„± (í† í° ê¸¸ì´ ì œí•œìš©)
    # ------------------------------------------------------------------
    def _build_short_prompt(self, prediction_result=None, features_info=None,
                           morph_summary=None):
        """í† í° ê¸¸ì´ ì œí•œì„ ìœ„í•œ ì§§ì€ í”„ë¡¬í”„íŠ¸"""
        prompt = "ì´ê²ƒì€ ìœ ë°©ì•” ì„¸í¬ í˜„ë¯¸ê²½ ì‚¬ì§„ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n\n"
        
        # ì˜ˆì¸¡ ê²°ê³¼ë§Œ ê°„ë‹¨íˆ ì¶”ê°€
        if prediction_result:
            pred = prediction_result.get("prediction", "")
            malignant_prob = prediction_result.get("malignant_prob", 0)
            benign_prob = prediction_result.get("benign_prob", 0)
            prompt += f"ì˜ˆì¸¡: {pred} (ì•…ì„± {malignant_prob:.1%}, ì–‘ì„± {benign_prob:.1%})\n"
        
        # ì •ëŸ‰ ë¶„ì„ ìš”ì•½ë§Œ ê°„ë‹¨íˆ ì¶”ê°€
        if morph_summary and morph_summary.get("total_cells", 0) > 0:
            total = morph_summary["total_cells"]
            ir_ratio = morph_summary["irregular_boundary_ratio"] * 100
            lg_ratio = morph_summary["large_cell_ratio"] * 100
            prompt += f"ì„¸í¬ {total}ê°œ, ë¶ˆê·œì¹™ ê²½ê³„ {ir_ratio:.1f}%, í° ì„¸í¬ {lg_ratio:.1f}%\n"
        
        prompt += "\nì„¸í¬ì˜ í˜•íƒœ, í¬ê¸°, í•µì˜ íŠ¹ì§•ì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        return prompt

    # ------------------------------------------------------------------
    # ì˜ˆì¸¡ + íŠ¹ì§• ìš”ì•½ ì„¹ì…˜
    # ------------------------------------------------------------------
    def _build_prediction_feature_summary(self, prediction_result, features_info):
        md = "## ëª¨ë¸ ì˜ˆì¸¡ ë° íŠ¹ì§• ìš”ì•½\n\n"

        # ì˜ˆì¸¡ ê²°ê³¼
        if prediction_result:
            pred = prediction_result.get("prediction", "ì•Œ ìˆ˜ ì—†ìŒ")
            prob = prediction_result.get("probability", 0)
            malignant_prob = prediction_result.get("malignant_prob", 0)
            benign_prob = prediction_result.get("benign_prob", 0)

            md += "### ì˜ˆì¸¡ ê²°ê³¼\n"
            md += f"- **ì§„ë‹¨ ë°©í–¥(ëª¨ë¸ ì¶œë ¥)**: {pred}\n"
            md += f"- **ì „ì²´ í™•ë¥ **: {prob:.2%}\n"
            md += f"- **ì•…ì„± ìª½ìœ¼ë¡œ ê¸°ìš´ í™•ë¥ **: {malignant_prob:.2%}\n"
            md += f"- **ì–‘ì„± ìª½ìœ¼ë¡œ ê¸°ìš´ í™•ë¥ **: {benign_prob:.2%}\n\n"

        # ë³‘ë¦¬í•™ì  ì˜ë¯¸ë¥¼ ë¶™ì´ê¸° ìœ„í•œ ê°„ë‹¨í•œ ë§µ
        patho_notes = {
            "radius_mean": "ì¢…ì–‘ ë©ì–´ë¦¬ì˜ í‰ê·  í¬ê¸°(ë°˜ê²½)ì— í•´ë‹¹í•˜ë©°, ì•…ì„± ë³‘ë³€ì¼ìˆ˜ë¡ ì „ë°˜ì ì¸ í¬ê¸°ê°€ ì»¤ì§€ëŠ” ê²½í–¥ê³¼ ê´€ë ¨ë©ë‹ˆë‹¤.",
            "radius_worst": "ê°€ì¥ í° ì„¸í¬/ë©ì–´ë¦¬ì˜ í¬ê¸°ë¥¼ ë°˜ì˜í•˜ë©°, ê³ ì•…ì„± ë³‘ë³€ì—ì„œ ëŒ€í˜• ì„¸í¬ ë˜ëŠ” ì¢…ê´´ê°€ ë™ë°˜ë˜ëŠ” ì†Œê²¬ê³¼ ì—°ê²°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "area_mean": "ì„¸í¬ ë˜ëŠ” êµ°ì§‘ì˜ í‰ê·  ë©´ì ì„ ë‚˜íƒ€ë‚´ë©°, ë©ì–´ë¦¬ê°€ í´ìˆ˜ë¡ ì•…ì„± ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§€ëŠ” ê²½í–¥ê³¼ ì—°ê´€ë©ë‹ˆë‹¤.",
            "area_worst": "ê°€ì¥ í° êµ°ì§‘/ì„¸í¬ì˜ ë©´ì ì„ ë°˜ì˜í•˜ë©°, êµ­ì†Œì ìœ¼ë¡œ ë§¤ìš° í° ë³‘ë³€ì´ ìˆëŠ”ì§€ì™€ ê´€ë ¨ë©ë‹ˆë‹¤.",
            "perimeter_mean": "ì„¸í¬/êµ°ì§‘ì˜ ë‘˜ë ˆ ê¸¸ì´ë¥¼ ë‚˜íƒ€ë‚´ë©°, ë¶ˆê·œì¹™í•œ ê²½ê³„ê°€ ë§ì„ìˆ˜ë¡ ê¸¸ì–´ì§€ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.",
            "concavity_mean": "ì„¸í¬/êµ°ì§‘ ê²½ê³„ì˜ 'íŒŒê³ ë“  ì •ë„'ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì•…ì„±ì—ì„œ ë” ë¶ˆê·œì¹™í•œ ê²½ê³„ì™€ ì—°ê´€ë©ë‹ˆë‹¤.",
            "concave_points_mean": "ê²½ê³„ê°€ ì•ˆìª½ìœ¼ë¡œ êº¾ì´ëŠ” í¬ì¸íŠ¸ ê°œìˆ˜ë¡œ, í†±ë‹ˆ ëª¨ì–‘ì˜ ë¶ˆê·œì¹™í•œ ê²½ê³„ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤.",
            "texture_contrast_mean": "í•µ/ì„¸í¬ì§ˆ ë‚´ ëª…ì•” ëŒ€ë¹„ë¥¼ ë°˜ì˜í•˜ë©°, í•µ ì—¼ìƒ‰ì´ ë¶ˆê· ì¼í•˜ê±°ë‚˜ ì§„í•œ ì„¸í¬ê°€ ë§ì„ìˆ˜ë¡ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "texture_homogeneity_mean": "í…ìŠ¤ì²˜ì˜ ê· ì§ˆì„±ì„ ì˜ë¯¸í•˜ë©°, ê°’ì´ ë‚®ì„ìˆ˜ë¡ ì¡°ì§ì´ ë” ë¶ˆê· ì§ˆí•˜ê³  ë³µì¡í•œ íŒ¨í„´ì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "mean_intensity_mean": "í‰ê·  ë°ê¸°ë¡œ, ì—¼ìƒ‰ ê°•ë„ ë° ì„¸í¬ ë°€ë„ì™€ ê´€ë ¨ëœ ê°„ì ‘ ì§€í‘œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        }

        if features_info and features_info.get("top_features"):
            md += "### ì¤‘ìš” íŠ¹ì§• ê¸°ì—¬ë„ (SHAP/LIME ê¸°ë°˜)\n\n"
            md += "ëª¨ë¸ì´ ì˜ˆì¸¡ì„ ë‚´ë¦´ ë•Œ íŠ¹íˆ í¬ê²Œ ì°¸ê³ í•œ íŠ¹ì§•ë“¤ê³¼ ê·¸ ë³‘ë¦¬í•™ì  ì˜ë¯¸ë¥¼ í•¨ê»˜ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤:\n\n"

            for i, feat in enumerate(features_info["top_features"][:5], 1):
                name = feat["feature"]
                contrib = feat["contribution"]
                direction = "ê°’ì´ í´ìˆ˜ë¡ **ì•…ì„± ìª½**ìœ¼ë¡œ ê¸°ì—¬" if contrib > 0 else "ê°’ì´ í´ìˆ˜ë¡ **ì–‘ì„± ìª½**ìœ¼ë¡œ ê¸°ì—¬"

                # ë³‘ë¦¬ ì½”ë©˜íŠ¸
                note = None
                # ê¸°ë³¸ í‚¤ ê·¸ëŒ€ë¡œê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•´ ì ‘ë‘ì‚¬/ì ‘ë¯¸ì‚¬ ì œê±° í›„ ë§¤ì¹­ ì‹œë„
                if name in patho_notes:
                    note = patho_notes[name]
                else:
                    base_key = (
                        name.replace("_mean", "")
                            .replace("_se", "")
                            .replace("_worst", "")
                    )
                    for k in patho_notes.keys():
                        if base_key in k:
                            note = patho_notes[k]
                            break

                md += f"{i}. **{name}**: ê¸°ì—¬ë„ {abs(contrib):.4f} ({direction})\n"
                if note:
                    md += f"   - ë³‘ë¦¬í•™ì  í•´ì„: {note}\n"

            md += "\n"

        if not prediction_result and not (features_info and features_info.get("top_features")):
            md += "- ì˜ˆì¸¡ ê²°ê³¼ ë° íŠ¹ì§• ì •ë³´ê°€ ì „ë‹¬ë˜ì§€ ì•Šì•„, ëª¨ë¸ ê´€ì ì˜ í•´ì„ì€ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"

        return md

    # ------------------------------------------------------------------
    # í˜•íƒœ ì •ëŸ‰ ë¶„ì„ ë¦¬í¬íŠ¸ ì„¹ì…˜
    # ------------------------------------------------------------------
    def _build_morphology_summary_md(self, morph_summary):
        if not morph_summary or morph_summary.get("total_cells", 0) == 0:
            return ""

        total = morph_summary["total_cells"]
        ir_cnt = morph_summary["irregular_boundary_cells"]
        ir_ratio = morph_summary["irregular_boundary_ratio"] * 100
        lg_cnt = morph_summary["large_cells"]
        lg_ratio = morph_summary["large_cell_ratio"] * 100
        hc_cnt = morph_summary["high_contrast_cells"]
        hc_ratio = morph_summary["high_contrast_ratio"] * 100

        md = "## ì„¸í¬ í˜•íƒœ ì •ëŸ‰ ë¶„ì„ (ì´ë¯¸ì§€ ê¸°ë°˜)\n\n"
        md += f"- ê°ì§€ëœ ì„¸í¬ëŠ” ì´ **{total}ê°œ**ì…ë‹ˆë‹¤.\n"
        md += f"- ì´ ì¤‘ **ê²½ê³„ê°€ ë“¤ì­‰ë‚ ì‘¥í•œ ì„¸í¬**(ì›í˜•ë„ ê°ì†Œ, convexity/solidity ê°ì†Œ)ëŠ” ì•½ **{ir_ratio:.1f}%**ì¸ **{ir_cnt}ê°œ**ì…ë‹ˆë‹¤.\n"
        md += f"- **ìƒëŒ€ì ìœ¼ë¡œ í° ì„¸í¬(ë©´ì  ìƒìœ„ 25%)**ëŠ” ì•½ **{lg_ratio:.1f}%**ì¸ **{lg_cnt}ê°œ**ì…ë‹ˆë‹¤.\n"
        md += f"- **í…ìŠ¤ì²˜ ëŒ€ë¹„(ëª…ì•” ë³€í™”)ê°€ ë†’ì€ ì„¸í¬**ëŠ” ì•½ **{hc_ratio:.1f}%**ì¸ **{hc_cnt}ê°œ**ì…ë‹ˆë‹¤.\n\n"

        # ì •ëŸ‰ê°’ì„ ì´ìš©í•´ ë³‘ë¦¬í•™ì  ì¸ìƒ ì½”ë©˜íŠ¸(ì™„ì „ ì§„ë‹¨ì€ ì•„ë‹˜)
        md += "### ë³‘ë¦¬í•™ì  ê´€ì ì—ì„œì˜ í•´ì„ì  ì½”ë©˜íŠ¸\n\n"

        # ê²½ê³„ ë¶ˆê·œì¹™ ë¹„ìœ¨ ì½”ë©˜íŠ¸
        if ir_ratio < 15:
            md += "- ê²½ê³„ê°€ ë¶ˆê·œì¹™í•œ ì„¸í¬ ë¹„ìœ¨ì´ ë¹„êµì  ë‚®ì•„, ì „ì²´ì ìœ¼ë¡œëŠ” **ê²½ë„ ì´í˜•ì„± ë˜ëŠ” ì–‘ì„± ë³€í™”ì— ê°€ê¹Œìš´ ê²½ê³„ íŒ¨í„´**ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
        elif ir_ratio < 40:
            md += "- ê²½ê³„ê°€ ë¶ˆê·œì¹™í•œ ì„¸í¬ê°€ ì¼ì • ë¹„ìœ¨ ì¡´ì¬í•˜ì—¬, **ë¶€ë¶„ì ìœ¼ë¡œ ë¹„ì •í˜• ì„¸í¬ê°€ ì„ì—¬ ìˆëŠ” ì¤‘ê°„ ì •ë„ì˜ ì´í˜•ì„± íŒ¨í„´**ìœ¼ë¡œ í•´ì„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
        else:
            md += "- ê²½ê³„ê°€ ë“¤ì‘¥ë‚ ì‘¥í•œ ì„¸í¬ ë¹„ìœ¨ì´ ìƒë‹¹íˆ ë†’ì•„, **ê³ ë„ ì´í˜•ì„± ë˜ëŠ” ì•…ì„±ì— ê°€ê¹Œìš´ ê²½ê³„ ë¶ˆê·œì¹™ íŒ¨í„´**ì´ ê´€ì°°ë  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n"

        # í° ì„¸í¬ ë¹„ìœ¨ ì½”ë©˜íŠ¸
        if lg_ratio < 15:
            md += "- í° ì„¸í¬ ë¹„ìœ¨ì´ ë‚®ì•„, ì„¸í¬ í¬ê¸° ë¶„í¬ëŠ” ë¹„êµì  ê· ì¼í•œ í¸ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n"
        elif lg_ratio < 40:
            md += "- í° ì„¸í¬ê°€ ëˆˆì— ë„ê²Œ ì¡´ì¬í•˜ì§€ë§Œ ê·¹ë‹¨ì ìœ¼ë¡œ ë§ì§€ëŠ” ì•Šì•„, **ì¤‘ë“±ë„ ì •ë„ì˜ ì„¸í¬ í¬ê¸° ë³€í™”(pleomorphism)**ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
        else:
            md += "- í° ì„¸í¬ ë¹„ìœ¨ì´ ë†’ì•„, **ì„¸í¬ í¬ê¸° ë‹¤í˜•ì„±ì´ ëšœë ·í•œ íŒ¨í„´**ìœ¼ë¡œ ì•…ì„± ë³€í™”ì™€ ë” ì˜ ë§ëŠ” ì–‘ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"

        # ê³ ëŒ€ë¹„ í…ìŠ¤ì²˜ ë¹„ìœ¨ ì½”ë©˜íŠ¸
        if hc_ratio < 15:
            md += "- í…ìŠ¤ì²˜ ëŒ€ë¹„ê°€ ë†’ì€ ì„¸í¬ ë¹„ìœ¨ì´ ë‚®ì•„, í•µ ì—¼ìƒ‰ ê°•ë„ë‚˜ ëª…ì•” ì°¨ì´ëŠ” ë¹„êµì  ê· ì¼í•œ í¸ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\n"
        elif hc_ratio < 40:
            md += "- í…ìŠ¤ì²˜ ëŒ€ë¹„ê°€ ë†’ì€ ì„¸í¬ê°€ ë¶€ë¶„ì ìœ¼ë¡œ ì¡´ì¬í•˜ì—¬, ì¼ë¶€ ì˜ì—­ì—ì„œ **í•µ ì—¼ìƒ‰ ê°•ë„ê°€ ë” ì§„í•˜ê±°ë‚˜ ë¶ˆê· ì¼í•œ ì†Œê²¬**ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
        else:
            md += "- í…ìŠ¤ì²˜ ëŒ€ë¹„ê°€ ë†’ì€ ì„¸í¬ ë¹„ìœ¨ì´ ë†’ì•„, **í•µ ì—¼ìƒ‰ì´ ë¶ˆê· ì¼í•˜ê±°ë‚˜ ê±°ì¹œ í¬ë¡œë§ˆí‹´ íŒ¨í„´**ì´ ê´‘ë²”ìœ„í•˜ê²Œ ì¡´ì¬í•  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n"

        md += (
            "\nì¼ë°˜ì ìœ¼ë¡œ ì•…ì„± ë³‘ë³€ì—ì„œëŠ”\n"
            "- ê²½ê³„ê°€ ë¶ˆê·œì¹™í•œ ì„¸í¬ ë¹„ìœ¨ì´ ì¦ê°€í•˜ê³ ,\n"
            "- í¬ê¸°ê°€ í° ì„¸í¬ì™€ ì‘ì€ ì„¸í¬ê°€ ì„ì—¬ ë‚˜íƒ€ë‚˜ë©°(ì„¸í¬/í•µ ë‹¤í˜•ì„±),\n"
            "- í•µ ì—¼ìƒ‰ì´ ë” ì§„í•˜ê±°ë‚˜ ë¶ˆê· ì¼í•œ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n"
            "ìœ„ ì •ëŸ‰ ë¶„ì„ì€ ì´ëŸ¬í•œ ë³‘ë¦¬í•™ì  íŒ¨í„´ì´ ì–´ëŠ ì •ë„ ì¡´ì¬í•˜ëŠ”ì§€ **ì •ëŸ‰ì  ë‹¨ì„œ**ë¥¼ ì œê³µí•˜ë©°, "
            "ì‹¤ì œ ìŠ¬ë¼ì´ë“œ íŒë… ì‹œ ìœ¡ì•ˆ ì†Œê²¬ê³¼ í•¨ê»˜ ì°¸ê³ ë˜ëŠ” ë³´ì¡° ì§€í‘œë¡œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            "â€» ì´ ë¶„ì„ì€ ì—°êµ¬Â·êµìœ¡ ëª©ì ì˜ ì •ëŸ‰ ìš”ì•½ì´ë©°, ë‹¨ë…ìœ¼ë¡œ ì„ìƒ ì§„ë‹¨ì— ì‚¬ìš©ë˜ì–´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.\n"
        )

        return md

    # ------------------------------------------------------------------
    # VLMì´ ì•„ì˜ˆ ì•ˆë  ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ì„¤ëª…
    # ------------------------------------------------------------------
    def _generate_fallback_visual_description(self):
        return (
            "VLM ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í•´, ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë¶„ì„í•œ ì„¤ëª…ì„ ì œê³µí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. "
            "ë‹¤ë§Œ ì•„ë˜ ì˜ˆì¸¡ ê²°ê³¼, íŠ¹ì§• ì¤‘ìš”ë„, ì„¸í¬ í˜•íƒœ ì •ëŸ‰ ë¶„ì„ì„ í•¨ê»˜ ì°¸ê³ í•˜ì—¬ "
            "ì„¸í¬ì˜ í¬ê¸°Â·í˜•íƒœÂ·ë°€ì§‘ë„Â·ê²½ê³„ ë¶ˆê·œì¹™ì„±, í•µ ì—¼ìƒ‰ íŒ¨í„´ ë“±ì„ ë³‘ë¦¬í•™ì ìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )


# ì „ì—­ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_vlm_instance = None


def get_vlm_explainer():
    global _vlm_instance
    if _vlm_instance is None:
        _vlm_instance = VLMExplainer()
    return _vlm_instance
