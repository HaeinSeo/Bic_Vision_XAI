"""
ìœ ë°©ì•” ì´ë¯¸ì§€ ë¶„ì„ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
XAI (SHAP)ë¥¼ ì‚¬ìš©í•œ ì„¤ëª… ê°€ëŠ¥í•œ AI ì‹œìŠ¤í…œ
"""
from flask import Flask, render_template, request, jsonify, send_file
import os
import base64
import io
from PIL import Image
import numpy as np
import cv2
from model_utils import BreastCancerModel
from image_utils import extract_image_features, draw_bbox_with_labels, load_image, preprocess_image, detect_cells
from image_classifier import ImageClassifier
# vlm_utilsëŠ” ì§€ì—° ë¡œë”© (torch DLL ë¬¸ì œ ë°©ì§€)
import matplotlib
matplotlib.use('Agg')  # GUI ë°±ì—”ë“œ ì‚¬ìš© ì•ˆ í•¨
import matplotlib.pyplot as plt

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB ì œí•œ

# í•œê¸€ ì¸ì½”ë”© ì„¤ì •
app.config['JSON_AS_ASCII'] = False

# ì—…ë¡œë“œ í´ë” ìƒì„±
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs('static/results', exist_ok=True)

# ëª¨ë¸ ë¡œë“œ
print("ëª¨ë¸ ë¡œë“œ ì¤‘...")
model = BreastCancerModel()
try:
    model.load_model()
except:
    print("ëª¨ë¸ í•™ìŠµ ì¤‘...")
    model.train_model()
    model.save_model()

# ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ (CNN ê¸°ë°˜)
print("ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì¤‘...")
image_classifier = ImageClassifier()
image_model_loaded = image_classifier.load_model()

if not image_model_loaded:
    print("âš ï¸ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    try:
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        import torch
        if torch.cuda.is_available():
            print(f"âœ… GPU ì‚¬ìš©: {torch.cuda.get_device_name(0)}")
        else:
            print("âš ï¸ CPU ì‚¬ìš© (í•™ìŠµì´ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        # ì´ë¯¸ì§€ì—ì„œ ì§ì ‘ í•™ìŠµ
        success = image_classifier.train(image_dir="image/Images", epochs=15, batch_size=8)
        if success:
            print("âœ… ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        else:
            print("âš ï¸ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
            image_classifier = None
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
        image_classifier = None
else:
    print("âœ… ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# VLM ëª¨ë¸ì€ í•„ìš”í•  ë•Œë§Œ ë¡œë“œ (ì§€ì—° ë¡œë”©)
vlm_explainer = None
print("âš ï¸ VLM ëª¨ë¸ì€ ì²« ì‚¬ìš© ì‹œ ë¡œë“œë©ë‹ˆë‹¤ (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    """ì´ë¯¸ì§€ ì˜ˆì¸¡ ë° ì„¤ëª… ìƒì„±"""
    try:
        if 'image' not in request.files:
            return jsonify({'error': 'ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400
        
        # íŒŒì¼ ì €ì¥
        filename = file.filename
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        # íŒŒì¼ëª…ì—ì„œ ì‹¤ì œ ë ˆì´ë¸” ì¶”ì¶œ (ê²€ì¦ìš©)
        actual_label = None
        if 'benign' in filename.lower():
            actual_label = 'ì–‘ì„±(B)'
        elif 'malignant' in filename.lower():
            actual_label = 'ì•…ì„±(M)'
        
        # ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ (ì„¸í¬ ê°ì§€ìš©)
        print(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {filename}")
        if actual_label:
            print(f"íŒŒì¼ëª… ê¸°ë°˜ ì‹¤ì œ ë ˆì´ë¸”: {actual_label}")
        
        features, cells, processed_img = extract_image_features(filepath)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰ - ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ìš°ì„  ì‚¬ìš©
        if image_classifier is not None and image_classifier.model is not None:
            try:
                print("ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸(CNN) ì‚¬ìš© ì¤‘...")
                prediction = image_classifier.predict(filepath)
                prediction_method = "CNN (ì´ë¯¸ì§€ ì§ì ‘ í•™ìŠµ)"
                use_cnn = True
            except Exception as e:
                print(f"âš ï¸ CNN ì˜ˆì¸¡ ì‹¤íŒ¨: {e}, ìˆ˜ì¹˜ ê¸°ë°˜ ëª¨ë¸ ì‚¬ìš©")
                if features is None:
                    return jsonify({'error': 'ì´ë¯¸ì§€ì—ì„œ ì„¸í¬ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 400
                prediction = model.predict(features)
                prediction_method = "ìˆ˜ì¹˜ ê¸°ë°˜ (íŠ¹ì§• ì¶”ì¶œ)"
                use_cnn = False
        else:
            print("ìˆ˜ì¹˜ ê¸°ë°˜ ëª¨ë¸ ì‚¬ìš© ì¤‘...")
            if features is None:
                return jsonify({'error': 'ì´ë¯¸ì§€ì—ì„œ ì„¸í¬ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 400
            prediction = model.predict(features)
            prediction_method = "ìˆ˜ì¹˜ ê¸°ë°˜ (íŠ¹ì§• ì¶”ì¶œ)"
            use_cnn = False
        
        # ì‹¤ì œ ë ˆì´ë¸”ê³¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ í™•ì¸
        if actual_label:
            predicted_label = prediction['prediction']
            is_correct = actual_label == predicted_label
            print(f"ì˜ˆì¸¡: {predicted_label}, ì‹¤ì œ: {actual_label}, ì •í™•ë„: {'âœ“' if is_correct else 'âœ—'}")
            if not is_correct:
                print(f"âš ï¸ ë¶„ë¥˜ ì˜¤ë¥˜ ê°ì§€! ì˜ˆì¸¡ í™•ë¥ : {prediction['probability']:.2%}")
        
        # SHAP ì„¤ëª… ìƒì„±
        if use_cnn:
            # CNN ì‚¬ìš© ì‹œ ìˆ˜ì¹˜ ê¸°ë°˜ ì„¤ëª…ë„ í•¨ê»˜ ì œê³µ (ì„¸í¬ê°€ ê°ì§€ëœ ê²½ìš°)
            if features is not None and len(cells) > 0:
                explanation = model.explain(features)
            else:
                explanation = {
                    'top_features': [],
                    'all_features': [],
                    'method': 'CNN'
                }
        else:
            explanation = model.explain(features)
        
        # ê° ì„¸í¬ë³„ ì˜ˆì¸¡ (ê°„ë‹¨í•œ ë²„ì „ - ì „ì²´ ì´ë¯¸ì§€ ì˜ˆì¸¡ì„ ê° ì„¸í¬ì— ì ìš©)
        cell_predictions = []
        cell_explanations = []
        for i, cell in enumerate(cells):
            cell_predictions.append(prediction)
            cell_explanations.append(explanation)
        
        # ë°•ìŠ¤ ì •ë³´ ì¶”ì¶œ (ë™ì  ë Œë”ë§ì„ ìœ„í•´)
        boxes_data = []
        for i, cell in enumerate(cells):
            x, y, w, h = cell['bbox']
            pred = cell_predictions[i] if i < len(cell_predictions) else None
            expl = cell_explanations[i] if i < len(cell_explanations) else None
            
            # ì˜ˆì¸¡ ì •ë³´
            is_malignant = 'ì•…ì„±' in pred['prediction'] if pred else False
            prob = pred['probability'] if pred else 0
            label = pred['prediction'] if pred else 'ì„¸í¬'
            color = '#ff6b6b' if is_malignant else '#51cf66' if pred else '#888888'
            
            # íŠ¹ì§• ì •ë³´
            top_features = []
            if expl and 'top_features' in expl:
                top_features = expl['top_features'][:3]
            
            # Contour ì •ë³´ ì¶”ì¶œ
            contours_data = []
            try:
                if 'full_mask' in cell:
                    mask = cell['full_mask']
                else:
                    mask = cell['mask']
                    full_mask = np.zeros((processed_img.shape[0], processed_img.shape[1]), dtype=np.uint8)
                    full_mask[y:y+h, x:x+w] = mask
                    mask = full_mask
                
                mask_uint8 = np.uint8(mask * 255)
                contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                for contour in contours:
                    if len(contour) >= 3:
                        # Contour ì¢Œí‘œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                        contour_points = contour.reshape(-1, 2).tolist()
                        contours_data.append(contour_points)
            except:
                pass
            
            boxes_data.append({
                'bbox': [int(x), int(y), int(w), int(h)],
                'label': label,
                'probability': float(prob),
                'is_malignant': is_malignant,
                'color': color,
                'top_features': top_features,
                'contours': contours_data
            })
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (ë°”ìš´ë”© ë°•ìŠ¤ë§Œ, segmentation ì œì™¸)
        from image_utils import draw_bbox_with_labels, draw_instance_segmentation, draw_mask_based_segmentation, load_mask_image
        result_img = draw_bbox_with_labels(processed_img, cells, cell_predictions, cell_explanations, show_segmentation=False)
        
        # Instance segmentation ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
        segmentation_img = draw_instance_segmentation(processed_img, cells, cell_predictions)
        
        # ë§ˆìŠ¤í¬ íŒŒì¼ ê¸°ë°˜ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
        mask_based_img = None
        mask_base64 = None
        mask_img = load_mask_image(filepath)
        if mask_img is not None:
            try:
                # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ (ì»¬ëŸ¬ ê°€ëŠ¥)
                original_img = load_image(filepath)
                if len(original_img.shape) == 3:
                    original_gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)
                else:
                    original_gray = original_img
                
                # ë§ˆìŠ¤í¬ ê¸°ë°˜ ì‹œê°í™” ìƒì„±
                mask_based_img = draw_mask_based_segmentation(original_gray, mask_img, cell_predictions)
                
                # ë§ˆìŠ¤í¬ ê¸°ë°˜ ì´ë¯¸ì§€ ì¸ì½”ë”©
                mask_buffer = io.BytesIO()
                mask_based_img.savefig(mask_buffer, format='png', bbox_inches='tight', dpi=150)
                mask_buffer.seek(0)
                mask_base64 = base64.b64encode(mask_buffer.getvalue()).decode('utf-8')
                plt.close(mask_based_img)
                print("âœ… ë§ˆìŠ¤í¬ ê¸°ë°˜ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ë§ˆìŠ¤í¬ ê¸°ë°˜ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
                mask_base64 = None
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        img_buffer = io.BytesIO()
        result_img.savefig(img_buffer, format='png', bbox_inches='tight', dpi=150)
        img_buffer.seek(0)
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
        plt.close(result_img)
        
        # Segmentation ì´ë¯¸ì§€ ì¸ì½”ë”©
        seg_buffer = io.BytesIO()
        segmentation_img.savefig(seg_buffer, format='png', bbox_inches='tight', dpi=150)
        seg_buffer.seek(0)
        seg_base64 = base64.b64encode(seg_buffer.getvalue()).decode('utf-8')
        plt.close(segmentation_img)
        
        # íŠ¹ì§• ê°’ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        feature_dict = {}
        for i, feat_name in enumerate(model.feature_names):
            feature_dict[feat_name] = float(features[i])
        
        # ì„¤ëª…ì— method ì¶”ê°€
        if 'method' not in explanation:
            explanation['method'] = 'Feature Importance'
        
        # VLM ì„¤ëª… ìƒì„± (ì§€ì—° ë¡œë”©)
        vlm_explanation = None
        try:
            # VLMì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ ì‹œë„
            global vlm_explainer
            if vlm_explainer is None:
                print("VLM ëª¨ë¸ ë¡œë“œ ì¤‘... (ì²˜ìŒ ì‚¬ìš© ì‹œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
                from vlm_utils import VLMExplainer
                try:
                    vlm_explainer = VLMExplainer()
                    if vlm_explainer.model is None:
                        print("âš ï¸ VLM ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        vlm_explainer = None
                except Exception as e:
                    print(f"âš ï¸ VLM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    vlm_explainer = None
            
            if vlm_explainer is not None and vlm_explainer.model is not None:
                try:
                    print("VLM ì„¤ëª… ìƒì„± ì¤‘...")
                    vlm_explanation = vlm_explainer.explain_image(filepath, prediction, explanation)
                    print(f"âœ… VLM ì„¤ëª… ìƒì„± ì™„ë£Œ: {vlm_explanation[:100] if vlm_explanation else 'None'}...")
                    if not vlm_explanation:
                        vlm_explanation = "VLM ì„¤ëª…ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                except Exception as e:
                    print(f"âš ï¸ VLM ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
                    import traceback
                    traceback.print_exc()
                    vlm_explanation = "VLM ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            else:
                vlm_explanation = "VLM ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”."
        except Exception as e:
            print(f"âš ï¸ VLM ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            vlm_explanation = None
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            'prediction': prediction['prediction'],
            'probability': prediction['probability'],
            'malignant_prob': prediction['malignant_prob'],
            'benign_prob': prediction['benign_prob'],
            'explanation': {
                'top_features': explanation.get('top_features', []),
                'all_features': explanation.get('all_features', []),
                'method': explanation.get('method', prediction_method)
            },
            'features': feature_dict if image_classifier is None else {},
            'image': f"data:image/png;base64,{img_base64}",
            'base_image': f"data:image/png;base64,{base64.b64encode(cv2.imencode('.png', processed_img)[1]).decode('utf-8')}",  # ì›ë³¸ ì´ë¯¸ì§€ (ë°•ìŠ¤ ì—†ìŒ)
            'boxes_data': boxes_data,  # ë°•ìŠ¤ ì •ë³´ (ë™ì  ë Œë”ë§ìš©)
            'segmentation_image': f"data:image/png;base64,{seg_base64}",
            'mask_based_image': f"data:image/png;base64,{mask_base64}" if mask_base64 else None,
            'num_cells': len(cells),
            'vlm_explanation': vlm_explanation if vlm_explanation else None,
            'actual_label': actual_label,  # ì‹¤ì œ ë ˆì´ë¸” (íŒŒì¼ëª… ê¸°ë°˜)
            'prediction_method': prediction_method  # ì‚¬ìš©ëœ ëª¨ë¸ ë°©ë²•
        }
        
        # VLM ì„¤ëª… ë¡œê·¸
        if vlm_explanation:
            print(f"ğŸ“¤ VLM ì„¤ëª… ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(vlm_explanation)})")
        
        return jsonify(response_data)
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': f'ì˜¤ë¥˜ ë°œìƒ: {str(e)}'}), 500

@app.route('/sample_images')
def sample_images():
    """ìƒ˜í”Œ ì´ë¯¸ì§€ ëª©ë¡ ë°˜í™˜"""
    image_dir = 'image/Images'
    sample_images = []
    
    if os.path.exists(image_dir):
        for filename in os.listdir(image_dir):
            if filename.endswith('.tif') and not filename.endswith('.xml'):
                # íŒŒì¼ëª…ì—ì„œ benign/malignant íŒë‹¨
                is_malignant = 'malignant' in filename.lower()
                sample_images.append({
                    'filename': filename,
                    'path': os.path.join(image_dir, filename),
                    'label': 'ì•…ì„±' if is_malignant else 'ì–‘ì„±'
                })
    
    return jsonify({'images': sample_images[:10]})  # ìµœëŒ€ 10ê°œë§Œ ë°˜í™˜

@app.route('/comparison_visualization')
def comparison_visualization():
    """ë¹„êµ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± (ì˜í•™ì  ìŠ¤íƒ€ì¼)"""
    try:
        from image_utils import load_image, preprocess_image, detect_cells, load_mask_image, detect_cells_from_mask
        import matplotlib.pyplot as plt
        import matplotlib.gridspec as gridspec
        import numpy as np
        
        # ìƒ˜í”Œ ì´ë¯¸ì§€ ì„ íƒ (ì–‘ì„±/ì•…ì„± í˜¼í•©)
        image_dir = 'image/Images'
        masks_dir = 'image/Masks'
        
        if not os.path.exists(image_dir):
            return jsonify({'error': 'ì´ë¯¸ì§€ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        # ìƒ˜í”Œ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
        sample_files = [
            'ytma49_111003_benign1_ccd.tif',
            'ytma49_111003_malignant1_ccd.tif',
            'ytma49_111003_benign2_ccd.tif',
            'ytma49_111003_malignant2_ccd.tif',
            'ytma49_111003_benign3_ccd.tif',
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ í•„í„°ë§
        available_samples = []
        for filename in sample_files:
            img_path = os.path.join(image_dir, filename)
            if os.path.exists(img_path):
                available_samples.append(filename)
            if len(available_samples) >= 5:
                break
        
        if len(available_samples) == 0:
            return jsonify({'error': 'ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        # ë¹„êµ ì‹œê°í™” ìƒì„±
        fig = plt.figure(figsize=(20, 12))
        gs = gridspec.GridSpec(len(available_samples) + 1, 5, figure=fig, 
                              hspace=0.4, wspace=0.3, 
                              left=0.05, right=0.95, top=0.95, bottom=0.05,
                              height_ratios=[0.5] + [1] * len(available_samples))
        
        # ì»¬ëŸ¼ í—¤ë”
        column_headers = ['Image', 'Red Channel', 'Ground Truth', 'Ours', 'Farsight']
        for col_idx, header in enumerate(column_headers):
            ax_header = fig.add_subplot(gs[0, col_idx])
            ax_header.text(0.5, 0.5, header, ha='center', va='center', 
                          fontsize=16, fontweight='bold', transform=ax_header.transAxes,
                          bbox=dict(boxstyle='round', facecolor='#667eea', alpha=0.2, edgecolor='#667eea', linewidth=2))
            ax_header.axis('off')
        
        for row_idx, filename in enumerate(available_samples):
            img_path = os.path.join(image_dir, filename)
            
            # ê° ì»¬ëŸ¼ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì˜¤ë¥˜ ê²©ë¦¬
            axes = []
            for col_idx in range(5):
                axes.append(fig.add_subplot(gs[row_idx + 1, col_idx]))
            
            try:
                # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
                img = load_image(img_path)
                if img is None or img.size == 0:
                    raise ValueError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
                
                # ì´ë¯¸ì§€ í˜•íƒœ í™•ì¸ ë° ë³€í™˜
                if len(img.shape) == 3:
                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                elif len(img.shape) == 2:
                    gray = img.copy()
                    img_rgb = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)
                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•íƒœ: {img.shape}")
                
                # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
                if gray.shape[0] == 0 or gray.shape[1] == 0:
                    raise ValueError(f"ì´ë¯¸ì§€ í¬ê¸°ê°€ 0ì…ë‹ˆë‹¤: {gray.shape}")
                
                # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ì¼ê´€ëœ í¬ê¸°ë¡œ)
                target_size = (400, 400)
                gray_resized = cv2.resize(gray, target_size)
                img_rgb_resized = cv2.resize(img_rgb, target_size)
                
                # 1. Image (ì›ë³¸)
                try:
                    axes[0].imshow(img_rgb_resized)
                    axes[0].axis('off')
                    label = 'Benign' if 'benign' in filename.lower() else 'Malignant'
                    axes[0].set_title(f'Sample {row_idx + 1} ({label})', fontsize=11, fontweight='bold', pad=8)
                except Exception as e:
                    print(f"âš ï¸ Image ì»¬ëŸ¼ ì˜¤ë¥˜: {e}")
                    axes[0].text(0.5, 0.5, 'Error', ha='center', va='center', 
                                transform=axes[0].transAxes, fontsize=12, color='red', fontweight='bold')
                    axes[0].axis('off')
                
                # 2. Red Channel (ê·¸ë ˆì´ìŠ¤ì¼€ì¼)
                try:
                    axes[1].imshow(gray_resized, cmap='gray')
                    axes[1].axis('off')
                except Exception as e:
                    print(f"âš ï¸ Red Channel ì»¬ëŸ¼ ì˜¤ë¥˜: {e}")
                    axes[1].text(0.5, 0.5, 'Error', ha='center', va='center', 
                                transform=axes[1].transAxes, fontsize=12, color='red', fontweight='bold')
                    axes[1].axis('off')
                
                # 3. Ground Truth (ë§ˆìŠ¤í¬ ê¸°ë°˜)
                try:
                    mask_img = load_mask_image(img_path)
                    if mask_img is not None and mask_img.size > 0:
                        # ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                        if len(mask_img.shape) == 3:
                            mask_gray = cv2.cvtColor(mask_img, cv2.COLOR_BGR2GRAY)
                        elif len(mask_img.shape) == 2:
                            mask_gray = mask_img.copy()
                        else:
                            mask_gray = None
                        
                        if mask_gray is not None and mask_gray.shape[0] > 0 and mask_gray.shape[1] > 0:
                            # ë§ˆìŠ¤í¬ í¬ê¸° ì¡°ì •
                            mask_gray_resized = cv2.resize(mask_gray, target_size)
                            
                            # ë§ˆìŠ¤í¬ì—ì„œ ê³ ìœ í•œ ì„¸í¬ ID ì°¾ê¸°
                            unique_values = np.unique(mask_gray_resized)
                            unique_values = unique_values[unique_values > 0]
                            
                            # ê° ì„¸í¬ë¥¼ í°ìƒ‰ìœ¼ë¡œ í‘œì‹œ (Ground Truth ìŠ¤íƒ€ì¼)
                            mask_display = np.zeros_like(gray_resized)
                            for cell_id in unique_values:
                                mask_display[mask_gray_resized == cell_id] = 255
                            
                            axes[2].imshow(gray_resized, cmap='gray', alpha=0.5)
                            axes[2].imshow(mask_display, cmap='gray', alpha=0.8)
                        else:
                            axes[2].imshow(gray_resized, cmap='gray')
                            axes[2].text(0.5, 0.5, 'Invalid Mask', ha='center', va='center', 
                                        transform=axes[2].transAxes, fontsize=10, color='orange', fontweight='bold')
                    else:
                        axes[2].imshow(gray_resized, cmap='gray')
                        axes[2].text(0.5, 0.5, 'No Mask', ha='center', va='center', 
                                    transform=axes[2].transAxes, fontsize=12, color='red', fontweight='bold')
                    axes[2].axis('off')
                except Exception as e:
                    print(f"âš ï¸ Ground Truth ì»¬ëŸ¼ ì˜¤ë¥˜: {e}")
                    axes[2].imshow(gray_resized, cmap='gray')
                    axes[2].text(0.5, 0.5, 'Error', ha='center', va='center', 
                                transform=axes[2].transAxes, fontsize=12, color='red', fontweight='bold')
                    axes[2].axis('off')
                
                # 4. Ours (í˜„ì¬ detect_cells ë°©ë²•)
                try:
                    cells_ours, processed, _ = detect_cells(img)
                    axes[3].imshow(gray_resized, cmap='gray')
                    
                    # ê° ì„¸í¬ë¥¼ ë‹¤ë¥¸ ìƒ‰ìœ¼ë¡œ í‘œì‹œ
                    if len(cells_ours) > 0:
                        colors = plt.cm.tab20(np.linspace(0, 1, min(20, len(cells_ours))))
                        overlay = np.zeros((gray_resized.shape[0], gray_resized.shape[1], 3), dtype=np.float32)
                        
                        for idx, cell in enumerate(cells_ours[:50]):  # ìµœëŒ€ 50ê°œë§Œ í‘œì‹œ
                            try:
                                x, y, w, h = cell['bbox']
                                # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶° ì¢Œí‘œ ìŠ¤ì¼€ì¼ë§
                                if gray.shape[0] > 0 and gray.shape[1] > 0:
                                    scale_x = target_size[0] / gray.shape[1]
                                    scale_y = target_size[1] / gray.shape[0]
                                else:
                                    continue
                                
                                if 'full_mask' in cell:
                                    mask = cell['full_mask']
                                    if mask is not None and mask.size > 0:
                                        mask_resized = cv2.resize(mask.astype(np.uint8), target_size)
                                    else:
                                        continue
                                else:
                                    mask = cell.get('mask')
                                    if mask is not None and mask.size > 0:
                                        full_mask = np.zeros((gray.shape[0], gray.shape[1]), dtype=np.uint8)
                                        if y + h <= gray.shape[0] and x + w <= gray.shape[1]:
                                            full_mask[y:y+h, x:x+w] = mask
                                        mask_resized = cv2.resize(full_mask, target_size)
                                    else:
                                        continue
                                
                                color = colors[idx % len(colors)]
                                mask_bool = mask_resized > 0
                                for c in range(3):
                                    overlay[:, :, c][mask_bool] = color[c]
                            except Exception as e:
                                continue  # ê°œë³„ ì…€ ì²˜ë¦¬ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                        
                        if np.any(overlay > 0):
                            axes[3].imshow(overlay, alpha=0.6)
                except Exception as e:
                    print(f"âš ï¸ Ours ì»¬ëŸ¼ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
                    axes[3].imshow(gray_resized, cmap='gray')
                    axes[3].text(0.5, 0.5, 'Error', ha='center', va='center', 
                                transform=axes[3].transAxes, fontsize=12, color='red', fontweight='bold')
                axes[3].axis('off')
                
                # 5. Farsight (ê°„ë‹¨í•œ connectedComponents ë°©ë²•)
                try:
                    processed_simple, _ = preprocess_image(img)
                    if processed_simple is not None and processed_simple.size > 0:
                        _, binary = cv2.threshold(processed_simple, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                        kernel = np.ones((3, 3), np.uint8)
                        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
                        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
                        
                        binary_resized = cv2.resize(binary, target_size)
                        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary_resized, connectivity=8)
                        
                        axes[4].imshow(gray_resized, cmap='gray')
                        
                        # ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ë‹¤ë¥¸ ìƒ‰ìœ¼ë¡œ í‘œì‹œ
                        if num_labels > 1:
                            colors_farsight = plt.cm.Set3(np.linspace(0, 1, min(12, num_labels)))
                            overlay_farsight = np.zeros((gray_resized.shape[0], gray_resized.shape[1], 3), dtype=np.float32)
                            
                            for i in range(1, min(num_labels, 50)):  # ìµœëŒ€ 50ê°œë§Œ í‘œì‹œ
                                try:
                                    area = stats[i, cv2.CC_STAT_AREA]
                                    if 20 <= area <= 20000:
                                        mask_farsight = (labels == i).astype(np.uint8)
                                        color = colors_farsight[i % len(colors_farsight)]
                                        mask_bool = mask_farsight > 0
                                        for c in range(3):
                                            overlay_farsight[:, :, c][mask_bool] = color[c]
                                except Exception:
                                    continue
                            
                            if np.any(overlay_farsight > 0):
                                axes[4].imshow(overlay_farsight, alpha=0.6)
                    else:
                        axes[4].imshow(gray_resized, cmap='gray')
                        axes[4].text(0.5, 0.5, 'Process Error', ha='center', va='center', 
                                    transform=axes[4].transAxes, fontsize=10, color='orange', fontweight='bold')
                except Exception as e:
                    print(f"âš ï¸ Farsight ì»¬ëŸ¼ ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
                    axes[4].imshow(gray_resized, cmap='gray')
                    axes[4].text(0.5, 0.5, 'Error', ha='center', va='center', 
                                transform=axes[4].transAxes, fontsize=12, color='red', fontweight='bold')
                axes[4].axis('off')
                
            except Exception as e:
                print(f"âš ï¸ ìƒ˜í”Œ {filename} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ì´ë¯¸ì§€ í‘œì‹œ
                for col_idx in range(5):
                    axes[col_idx].text(0.5, 0.5, f'Error\n{str(e)[:30]}', ha='center', va='center', 
                                       transform=axes[col_idx].transAxes, fontsize=10, color='red', fontweight='bold')
                    axes[col_idx].axis('off')
        
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        img_buffer = io.BytesIO()
        fig.savefig(img_buffer, format='png', bbox_inches='tight', dpi=150, facecolor='white')
        img_buffer.seek(0)
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
        plt.close(fig)
        
        return jsonify({'image': f"data:image/png;base64,{img_base64}"})
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': f'ë¹„êµ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/vlm_explain', methods=['POST'])
def vlm_explain():
    """VLMì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± (ë³„ë„ ì—”ë“œí¬ì¸íŠ¸)"""
    try:
        if 'image' not in request.files:
            return jsonify({'error': 'ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400
        
        # ì˜ˆì¸¡ ê²°ê³¼ ì •ë³´ ë°›ê¸°
        prediction_result = request.form.get('prediction_result')
        features_info = request.form.get('features_info')
        
        # íŒŒì¼ ì €ì¥
        filename = file.filename
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], f"vlm_{filename}")
        file.save(filepath)
        
        # VLM ì„¤ëª… ìƒì„± (ì§€ì—° ë¡œë”©)
        global vlm_explainer
        if vlm_explainer is None:
            try:
                from vlm_utils import get_vlm_explainer
                vlm_explainer = get_vlm_explainer()
            except Exception as e:
                print(f"âš ï¸ VLM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                vlm_explainer = None
        
        if vlm_explainer and vlm_explainer.is_available():
            import json
            pred_data = json.loads(prediction_result) if prediction_result else None
            feat_data = json.loads(features_info) if features_info else None
            
            explanation = vlm_explainer.explain_image(
                filepath,
                prediction_result=pred_data,
                features_info=feat_data
            )
            
            return jsonify({'explanation': explanation})
        else:
            return jsonify({'error': 'VLM ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 503
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': f'ì˜¤ë¥˜ ë°œìƒ: {str(e)}'}), 500

if __name__ == '__main__':
    print("=" * 50)
    print("ìœ ë°©ì•” ì´ë¯¸ì§€ ë¶„ì„ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘")
    print("=" * 50)
    print("ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5000 ì ‘ì†")
    print("=" * 50)
    app.run(debug=True, host='0.0.0.0', port=5000)

